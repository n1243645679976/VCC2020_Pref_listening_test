# VCC2020-Pref: A Crowdsourced Preference Listening Test Dataset for Speech Naturalness
## Overview
VCC2020-Pref is a large-scale, preference-based listening test dataset designed for evaluating the naturalness of speech generated by voice conversion systems in the Voice Conversion Challenge 2020 (VCC2020). It was constructed using crowdsourced annotations collected via Amazon Mechanical Turk, based on utterance pairs generated by 32 different voice conversion systems participating in the first task: voice conversion within the same language. Audio samples can be found in the [VCC2020 repository](https://github.com/nii-yamagishilab/VCC2020-listeningtest).

Listeners were asked to indicate which of the two utterances in each pair sounded more natural and to what degree. The resulting dataset enables robust and reproducible research in speech quality assessment, especially in preference modeling and pairwise comparison-based evaluation.

## Listening Test Protocol
- **Number of systems:** 32  
- **Preference scores collected:**  
  992 unique system pairs × 80 utterance pairs per system pair × 2 preference scores per utterance pair = 158720 preference scores
- **Design:** Matching-utterance design (each test compares two utterances generated from the same input utterance and target speaker, but by different voice conversion systems)  
- **Number of listeners:** 1,548  
- **Evaluations per listener:** Between 20 and 5,020 utterance pairs  

For each pair of utterances (Voice A and Voice B), listeners answered the following question:

“Which sample sounds more natural (i.e., human-sounding), and how much do they differ in naturalness?”

They selected one of four options:

|Option	|Score|
| ---- | ---- |
|Voice A is much better than Voice B	|1|
|Voice A is slightly better than Voice B	|2|
|Voice B is slightly better than Voice A	|3|
|Voice B is much better than Voice A	|4|

## Data Format
The dataset is provided as a CSV file with the following four columns:

| Column Name	|Description|
|---|---|
|wav1|	The audio sample of the first audio file (Voice A)|
|wav2|	The audio sample of the second audio file (Voice B)|
|preference|	Listener's preference score (1–4)|
|listener|	Anonymized listener ID |

## License
This dataset is released under the [Open Database License (ODbL)](https://opendatacommons.org/licenses/odbl/1-0/).
You are free to share, modify, and use the data, as long as you attribute the source and keep it open under the same license.

## Citation
If you use this dataset in your work, please cite the following paper:
```bibtex
@article{HU2025101799,
  title = {E2EPref: An end-to-end preference-based framework for speech quality assessment to alleviate bias in direct assessment scores},
  journal = {Computer Speech & Language},
  volume = {93},
  pages = {101799},
  year = {2025},
  issn = {0885-2308},
  doi = {https://doi.org/10.1016/j.csl.2025.101799},
  url = {https://www.sciencedirect.com/science/article/pii/S0885230825000245},
  author = {Cheng-Hung Hu and Yusuke Yasuda and Tomoki Toda}
}
```
